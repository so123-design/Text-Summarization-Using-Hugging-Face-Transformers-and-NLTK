{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Text Summarization Using Hugging Face Transformers and NLTK\n",
    "\n",
    "---\n",
    "\n",
    "### **Introduction**\n",
    "This project demonstrates a Python-based text summarization tool leveraging state-of-the-art Natural Language Processing (NLP) technologies. It combines the power of Hugging Face's Transformer library with NLTK for tokenization to create a robust abstractive summarization pipeline. This tool takes a large body of text as input and generates a concise summary, making it ideal for summarizing articles, reports, or any text-intensive documents.\n",
    "\n",
    "---\n",
    "\n",
    "### **Purpose and Objectives**\n",
    "The primary goal of this project is to:\n",
    "1. Showcase the ability to integrate modern NLP models into Python-based applications.\n",
    "2. Solve real-world challenges of information overload by summarizing lengthy texts into digestible summaries.\n",
    "3. Highlight the use of Hugging Face's pre-trained models for state-of-the-art performance.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Components and Explanation**\n",
    "\n",
    "#### 1. **Libraries Used**\n",
    "- **NLTK (Natural Language Toolkit):** \n",
    "  - Used for downloading and initializing the `punkt` tokenizer, which splits text into sentences. It ensures compatibility and efficient handling of textual inputs.\n",
    "- **Hugging Face Transformers:**\n",
    "  - The project utilizes the `pipeline` abstraction to simplify the implementation of pre-trained summarization models. These models use transformer architectures to perform abstractive summarization.\n",
    "\n",
    "#### 2. **Code Breakdown**\n",
    "1. **Importing Required Libraries**:\n",
    "   - `nltk` is imported for text tokenization, and `pipeline` is imported from the Transformers library to use pre-trained models.\n",
    "\n",
    "2. **Downloading the Tokenizer**:\n",
    "   - The `punkt` tokenizer is downloaded to split text into meaningful components for the summarization process.\n",
    "\n",
    "3. **Defining the Summarization Function**:\n",
    "   - `generate_summary` is a utility function that takes text input and optional parameters for maximum and minimum summary lengths.\n",
    "   - Internally, the function uses the Hugging Face summarizer pipeline to process and generate the summary.\n",
    "\n",
    "4. **Error Handling**:\n",
    "   - The function includes error handling to provide meaningful feedback in case of exceptions during summarization.\n",
    "\n",
    "5. **Main Program**:\n",
    "   - An example input text is provided to demonstrate the summarization process.\n",
    "   - The generated summary is printed to the console.\n",
    "\n",
    "#### 3. **Sample Input and Output**\n",
    "- **Input**: A detailed text about OpenAI's GPT-3 model, its features, and implications.\n",
    "- **Output**: A concise summary capturing the essence of the input text.\n",
    "\n",
    "---\n",
    "\n",
    "### **How It Works**\n",
    "1. Initialize the pre-trained summarization pipeline using Hugging Face.\n",
    "2. Tokenize and preprocess the input text.\n",
    "3. Apply the summarization pipeline to generate an abstractive summary based on the defined parameters.\n",
    "4. Return the summary for display or further use.\n",
    "\n",
    "---\n",
    "\n",
    "### **Applications**\n",
    "This project has multiple real-world applications, including:\n",
    "- Summarizing lengthy news articles, academic papers, or legal documents.\n",
    "- Generating brief summaries for reports or presentations.\n",
    "- Creating tools for efficient content review in research or business domains.\n",
    "\n",
    "---\n",
    "\n",
    "### **Code Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T17:20:08.102928Z",
     "iopub.status.busy": "2024-12-24T17:20:08.102531Z",
     "iopub.status.idle": "2024-12-24T17:20:12.198713Z",
     "shell.execute_reply": "2024-12-24T17:20:12.197508Z",
     "shell.execute_reply.started": "2024-12-24T17:20:08.102898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T17:20:19.266349Z",
     "iopub.status.busy": "2024-12-24T17:20:19.265961Z",
     "iopub.status.idle": "2024-12-24T17:20:23.325666Z",
     "shell.execute_reply": "2024-12-24T17:20:23.324294Z",
     "shell.execute_reply.started": "2024-12-24T17:20:19.266300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T17:20:30.336288Z",
     "iopub.status.busy": "2024-12-24T17:20:30.335944Z",
     "iopub.status.idle": "2024-12-24T17:20:34.414294Z",
     "shell.execute_reply": "2024-12-24T17:20:34.413141Z",
     "shell.execute_reply.started": "2024-12-24T17:20:30.336262Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.2.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-24T17:20:43.397156Z",
     "iopub.status.busy": "2024-12-24T17:20:43.396780Z",
     "iopub.status.idle": "2024-12-24T17:21:18.100815Z",
     "shell.execute_reply": "2024-12-24T17:21:18.099592Z",
     "shell.execute_reply.started": "2024-12-24T17:20:43.397127Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3d7ecb2f3143929c97b47f524c4f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9326e1cdbc6b4f95869bccbaadd3a547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0897a911f544c6b8b987a401490b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23fa53a088c24814af8d8118f96f0fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eabb28ced9b4697b4c836a8f335dc30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary:\n",
      " The OpenAI GPT-3 model has revolutionized the field of natural language processing . The model was trained on a massive dataset of text, including books, websites, and other text data sources . The resulting model can perform a wide range of language tasks, such as answering questions, writing essays, summarizing content, translating languages, and generating poetry .\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from transformers import pipeline\n",
    "\n",
    "# Download the punkt tokenizer models from nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize the Hugging Face summarization pipeline (Abstractive Summarizer)\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "def generate_summary(text: str, max_length: int = 150, min_length: int = 50):\n",
    "    \"\"\"\n",
    "    Function to generate a summary for the given text using a Hugging Face model.\n",
    "\n",
    "    Parameters:\n",
    "    - text: The input text to summarize.\n",
    "    - max_length: The maximum length of the summary (in tokens).\n",
    "    - min_length: The minimum length of the summary (in tokens).\n",
    "\n",
    "    Returns:\n",
    "    - Summary of the input text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Summarize the text\n",
    "        summary = summarizer(text, max_length=max_length, min_length=min_length, do_sample=False)\n",
    "        \n",
    "        # Return the summary text\n",
    "        return summary[0]['summary_text']\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example text (You can replace this with any large body of text)\n",
    "    input_text = \"\"\"\n",
    "    The OpenAI GPT-3 model, which is based on the transformer architecture, has revolutionized the field of natural language processing. \n",
    "    Its ability to understand and generate human-like text has made it one of the most powerful AI models in existence today. \n",
    "    The model was trained on a massive dataset of text, including books, websites, and other text data sources. \n",
    "    The resulting model can perform a wide range of language tasks, such as answering questions, writing essays, summarizing content, \n",
    "    translating languages, and even generating poetry. One of the key features of GPT-3 is its size, with 175 billion parameters, \n",
    "    which allows it to learn a vast amount of information from the data it was trained on. This has led to impressive results in various benchmarks,\n",
    "    but it also raises concerns about the ethical implications of such powerful AI models, including issues related to bias, privacy, and misuse.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate summary\n",
    "    summary = generate_summary(input_text)\n",
    "    print(\"Generated Summary:\")\n",
    "    print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Future Enhancements**\n",
    "1. **Interactive User Interface**: Add a web-based or desktop application for user-friendly interaction.\n",
    "2. **Custom Models**: Integrate fine-tuned models for specific domains like healthcare, legal, or finance.\n",
    "3. **Scalability**: Implement the application as a microservice using frameworks like Flask or FastAPI for deployment.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "This project demonstrates the practical use of advanced NLP models in summarization tasks, showcasing skills in Python, libraries like Hugging Face Transformers, and text processing with NLTK. It is a powerful addition to any portfolio, highlighting expertise in modern AI technologies and their applications.\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
